# Lecture 17
## Supervised Learning
We are given a training set of n examples where each (x,y) pair is generated by an unknown function y=f(x). Goal is to find a hypothesis h that approximates 
f. 

## Classification 
Classification is the task of learning classifier f. When the cardinality of the classifier's range is 2, then the task is known as binary classification, 
otherwise it's known as multi-class classification.

### Image Classification
Classify image as a cat or dog (binary classification).

## Decision Trees
Decision tree reaches an output (in the leaves) through a sequence of tess on the input attributes (in internal nodes). Decision trees can reprsent any 
classifier, but some may require a larger tree. 
```
def LEARN-DT(examples, feature, parent_examples):
  if examples = {}:
    return PLURALITY-VALUE(parent_examples)
  else if all examples hav ethe same label:
    return label
  else if features = {}:
    return PLURALITY-VALUE(examples)
  else:
    A = argmax IMPORTANCE(a, examples) // most important feature
    tree = new decision tree with root test A
    for each value v of A:
      new_examples = {e.A = v}
      subtree = LEARN-DT(new_examples, features\{A}, examples) // recursively decide on which features to branch on
      add branch to tree with label A = v and subtree
    return tree
```

## Infomration Gain
To instantiate the `IMPORTANCE` function, we use the notion of **entropy**. The entropy of V that takes each value v with probability P(v) is:  
`H(V) = sum over v of P(v) log(1/P(v)) = -sum over v of P(v) log(P(V))`.  
The entory of a Bernoulli random variable that is true with probability p is given by `B(q) = -(q*log(q) + (1-q)*log(1-q))`. 

If a training set contains p positive examples and n negative examples, the entropy of hte output variable is `H(Output) = B(p/(p+n))`. Feature A with d 
values divides the training set into d subsets, each with p_k positive examples and n_k negative examples. 
- information gain is not monotonically decreasing

## Model Selection
Choosing models that fit the training set too well can result in overfitting. The quality of the fit of a hypothesis h has error rate P(h(x) \neq f(x)). 
We divide data into three sets:
1. training set -- trains candidate models
2. validation set -- chooses among different models or hypothesis classes
3. test set -- performs an unbiased evaluation of the best model
